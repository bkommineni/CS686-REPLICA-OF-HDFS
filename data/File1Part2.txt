ated
When clients wish to store a new file, they will send a storage request to the controller, and it will reply with a list of destination storage nodes to send the chunks to. The Controller itself should never see any of the actual files, only their metadata.
The Controller is also responsible for detecting storage node failures and ensuring the system replication level is maintained. In your DFS, every chunk will be replicated twice for a total of 3 duplicate chunks. This means if a system goes down, you can re-route retrievals to a backup copy. You￢ﾀﾙll also maintain the replication level by creating more copies in the event of a failure.
Storage Node
Storage nodes are responsible for storing and retrieving file chunks. When a chunk is stored, it will be checksummed so on-disk corruption can be detected.
Some messages that your storage node could accept (although you are certainly free to design your own):
Store chunk [File name, Chunk Number, Chunk Data]
Retrieve chunk [File name, Chunk Number]
One alternative is creating unique identifiers for each chunk, in which case you wouldn￢ﾀﾙt need the file name + chunk number combo. In that case, you￢ﾀﾙll have to think about how you inform clients on how to reconstruct the file correctly.
Finally, the storage nodes will send a heartbeat to the controller periodically. The heartbeat includes chunk metadata to keep the Controller up to date, while also letting it know that the node is still alive. Heartbeats should be sent every 5 seconds and only include the latest changes at the node, not an entire list of its files. However, the Controller can also ask the storage nodes to send a complete file list (useful if the Controller failed and wants to rebuild its view of the system state). You can also include the amount of free space available at the node in your heartbeat messages so that the Controller has an idea of resource availability.
Client
The client￢ﾀﾙs main functions include:
Breaking files into chunks, asking th